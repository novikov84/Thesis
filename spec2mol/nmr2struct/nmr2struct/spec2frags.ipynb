{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "514d3a90-08aa-4ba8-895d-5ed291c035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e588e4ea-f337-474d-b3fb-9453014ba9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('processed_spec_data_sample.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4b304e6-c2db-4082-9048-54145b31c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spec2FragsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data : List[Dict[str, List[int]]]\n",
    "    ) -> None:\n",
    "        \n",
    "        self.spectrums = []\n",
    "        self.frags = []\n",
    "        \n",
    "        for cur in data:\n",
    "            self.spectrums.append(\n",
    "                torch.cat([\n",
    "                    torch.tensor([SPECS_BOS_TOKEN], dtype=torch.int64),\n",
    "                    self._get_labels_from_spectrum(\n",
    "                        torch.tensor(\n",
    "                            cur['spectrum'],\n",
    "                            dtype=torch.int64\n",
    "                        )\n",
    "                    ),\n",
    "                    torch.tensor([SPECS_EOS_TOKEN], dtype=torch.int64)\n",
    "                ])\n",
    "            )\n",
    "            self.frags.append(\n",
    "                torch.cat([\n",
    "                    torch.tensor([FRAGS_BOS_TOKEN], dtype=torch.int64),\n",
    "                    torch.tensor(\n",
    "                        cur['frags'],\n",
    "                        dtype=torch.int64\n",
    "                    ),\n",
    "                    torch.tensor([FRAGS_EOS_TOKEN], dtype=torch.int64)\n",
    "                ])\n",
    "            )\n",
    "\n",
    "    def _get_labels_from_spectrum(\n",
    "        self,\n",
    "        spectrum : torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        res = []\n",
    "        for idx in (spectrum > 0).nonzero().flatten():\n",
    "            res.extend([idx] * spectrum[idx])\n",
    "        return torch.stack(res)\n",
    "\n",
    "    def __len__(\n",
    "        self\n",
    "    ) -> int:\n",
    "        return len(self.spectrums)\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.spectrums[idx], self.frags[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50192d8e-363c-4ea7-8750-b5e32af0a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Spec2FragsDataset(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9b7fe9c-98b7-48fe-9f6d-09c41a2263c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([300,  68,  92, 169, 174, 176, 177, 190, 199, 301]),\n",
       " tensor([4000,  866,   13,   10,  855,   11, 4001]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d3861b6-5402-4f34-9a22-4b7a439ca84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = np.random.choice(np.arange(len(dataset)), int(0.8*len(dataset)), replace=False)\n",
    "val_mask = [True for _ in range(len(dataset))]\n",
    "for cur in train_idxs:\n",
    "    val_mask[cur] = False\n",
    "val_idxs = np.arange(len(dataset))[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea9d18fc-6f72-4ccb-8670-f68583ca34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert val_idxs.shape[0] + train_idxs.shape[0] == len(dataset)\n",
    "assert np.intersect1d(val_idxs, train_idxs).shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a3de097-7b58-4586-82ea-40b2ae201015",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.Subset(dataset, train_idxs)\n",
    "val_set = torch.utils.data.Subset(dataset, val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "166a5382-0ef5-43a4-aebc-59211f407e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_vocab_size = 300\n",
    "\n",
    "SPECS_BOS_TOKEN = specs_vocab_size\n",
    "SPECS_EOS_TOKEN = specs_vocab_size + 1\n",
    "SPECS_PAD_TOKEN = specs_vocab_size + 2\n",
    "\n",
    "# Correct\n",
    "frags_vocab_size = 5500\n",
    "FRAGS_BOS_TOKEN = frags_vocab_size\n",
    "FRAGS_EOS_TOKEN = frags_vocab_size + 1\n",
    "FRAGS_PAD_TOKEN = frags_vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f76277f7-1a06-4bd7-bef3-fb2ce3f77310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(\n",
    "    data : List[Tuple[torch.Tensor, torch.Tensor]]\n",
    "):\n",
    "    specs = []\n",
    "    frags = []\n",
    "    for cur in data:\n",
    "        specs.append(cur[0])\n",
    "        frags.append(cur[1])\n",
    "    return (\n",
    "        torch.nn.utils.rnn.pad_sequence(\n",
    "            specs, \n",
    "            batch_first=True, \n",
    "            padding_value=SPECS_PAD_TOKEN\n",
    "        ),\n",
    "        torch.nn.utils.rnn.pad_sequence(\n",
    "            frags, \n",
    "            batch_first=True, \n",
    "            padding_value=FRAGS_PAD_TOKEN\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "1f92dce1-cd71-4f04-9f5e-7a5fc40c6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0bbacf41-804c-4d90-9c17-268a127d2bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[300, 110, 115, 119, 155, 167, 183, 186, 188, 202, 301, 302],\n",
       "         [300,  70,  77,  86,  92, 117, 134, 202, 213, 220, 224, 301],\n",
       "         [300, 105, 176, 179, 179, 186, 219, 301, 302, 302, 302, 302],\n",
       "         [300,  59,  81, 166, 172, 176, 184, 185, 192, 223, 236, 301]]),\n",
       " tensor([[4000, 1585,  635, 1905,   19,   17,  791,  660,    5, 1343, 1260, 1584,\n",
       "          1236, 4001],\n",
       "         [4000, 1170,   90,  260, 1596,  612,  262,  756,   95, 3067,  265,  350,\n",
       "          4001, 5502],\n",
       "         [4000, 3423,   13, 3424,  926, 4919,  107,  102, 4001, 5502, 5502, 5502,\n",
       "          5502, 5502],\n",
       "         [4000,  131, 1271, 1846, 2134,  644,  619,    6,   12,  313,  133,  321,\n",
       "          4001, 5502]]))"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "04171917-1070-4fa8-915e-d812c824b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = torch.nn.Linear(d_model, d_model)\n",
    "        self.W_k = torch.nn.Linear(d_model, d_model)\n",
    "        self.W_v = torch.nn.Linear(d_model, d_model)\n",
    "        self.W_o = torch.nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "\n",
    "class PositionWiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = torch.nn.Linear(d_ff, d_model)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm2 = torch.nn.LayerNorm(d_model)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm2 = torch.nn.LayerNorm(d_model)\n",
    "        self.norm3 = torch.nn.LayerNorm(d_model)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = torch.nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = torch.nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = torch.nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = torch.nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = torch.nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != SPECS_PAD_TOKEN).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != FRAGS_PAD_TOKEN).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "4a2d72fb-843f-4a41-9697-8e2873c14be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    src_vocab_size=specs_vocab_size + 3,\n",
    "    tgt_vocab_size=frags_vocab_size + 3,\n",
    "    d_model=16,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    d_ff=32,\n",
    "    max_seq_length=100,\n",
    "    dropout=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5230accc-c616-44ab-aed4-2f8cd15df7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "acbf0a41-6c91-4c58-a8f9-e80ebbc5b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                 | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.7495367527008057\n",
      "2 3.792525291442871\n",
      "11 3.5020346641540527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▌                                                                                                                                                       | 1/100 [00:00<01:04,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0; Last train loss: 3.542299520969391; Last val loss: 4.964497804641724\n",
      "3 2.7574265003204346\n",
      "4 4.037358283996582\n",
      "11 3.8039982318878174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███                                                                                                                                                      | 2/100 [00:01<01:03,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 6.765056133270264\n",
      "3 4.436013221740723\n",
      "4 4.631419658660889\n",
      "Epoch 1; Last train loss: 3.568337595462799; Last val loss: 4.958754158020019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▌                                                                                                                                                    | 3/100 [00:01<01:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 3.2672338485717773\n",
      "1 5.330251216888428\n",
      "Epoch 2; Last train loss: 3.661420202255249; Last val loss: 4.949702024459839\n",
      "6 3.5975217819213867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████                                                                                                                                                   | 4/100 [00:02<00:58,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 3.456929922103882\n",
      "Epoch 3; Last train loss: 3.636236083507538; Last val loss: 4.94342303276062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▋                                                                                                                                                 | 5/100 [00:03<00:57,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 3.647644281387329\n",
      "0 3.6085426807403564\n",
      "2 6.758672714233398\n",
      "Epoch 4; Last train loss: 3.6618675351142884; Last val loss: 4.9473975658416744\n",
      "3 4.3535475730896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▋                                                                                                                                                 | 5/100 [00:03<01:04,  1.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[311], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m cur_train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.9\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lab_exps/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lab_exps/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/lab_exps/lib/python3.11/site-packages/torch/optim/adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    178\u001b[0m         group,\n\u001b[1;32m    179\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         state_steps,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     adamw(\n\u001b[1;32m    189\u001b[0m         params_with_grad,\n\u001b[1;32m    190\u001b[0m         grads,\n\u001b[1;32m    191\u001b[0m         exp_avgs,\n\u001b[1;32m    192\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    193\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    194\u001b[0m         state_steps,\n\u001b[1;32m    195\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    196\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    197\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    198\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    199\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    200\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    201\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    202\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    203\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    204\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    205\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    206\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    207\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    208\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/lab_exps/lib/python3.11/site-packages/torch/optim/adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 340\u001b[0m func(\n\u001b[1;32m    341\u001b[0m     params,\n\u001b[1;32m    342\u001b[0m     grads,\n\u001b[1;32m    343\u001b[0m     exp_avgs,\n\u001b[1;32m    344\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    345\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    346\u001b[0m     state_steps,\n\u001b[1;32m    347\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    348\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    349\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    350\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    351\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    352\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    353\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    354\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    355\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    356\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    357\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[1;32m    358\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    359\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/lab_exps/lib/python3.11/site-packages/torch/optim/adamw.py:471\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    469\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 471\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    473\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    cur_train_loss = []\n",
    "    cur_val_loss = []\n",
    "    \n",
    "    model.train()\n",
    "    for idx, (spectrum_train, frags_train) in enumerate(train_loader):\n",
    "        preds = model(\n",
    "            src=spectrum_train,\n",
    "            tgt=frags_train[:, :-1]\n",
    "        )\n",
    "        loss = criterion(\n",
    "            preds.view(-1, frags_vocab_size+3), \n",
    "            frags_train.contiguous()[:, 1:].reshape(-1)\n",
    "        )\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        cur_train_loss.append(loss.item())\n",
    "\n",
    "        if np.random.rand() > 0.9:\n",
    "            print(f\"{idx} {cur_train_loss[-1]}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for idx, (spectrum_val, frags_val) in enumerate(val_loader):\n",
    "            preds = model(\n",
    "                src=spectrum_val,\n",
    "                tgt=frags_val[:, :-1]\n",
    "            )\n",
    "            loss = criterion(\n",
    "                preds.view(-1, frags_vocab_size+3), \n",
    "                frags_val.contiguous()[:, 1:].reshape(-1)\n",
    "            )\n",
    "    \n",
    "            cur_val_loss.append(loss.item())\n",
    "\n",
    "            if np.random.rand() > 0.9:\n",
    "                print(f\"{idx} {cur_val_loss[-1]}\")\n",
    "\n",
    "    train_loss.append(np.mean(cur_train_loss))\n",
    "    val_loss.append(np.mean(cur_val_loss))\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}; Last train loss: {train_loss[-1]}; Last val loss: {val_loss[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
